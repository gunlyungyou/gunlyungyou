---
layout: single
title:  "Return Prediction Using Machine Learning"
categories:
  - Classification
toc: true
toc_sticky: true
toc_label: "Contents"
excerpt: "서비스 이탈자들의 복귀 확률을 예측하고 이를 마케팅에 활용하는 프로젝트에 대한 소개 페이지 입니다."
header:
  overlay_image: /assets/images/return.jpg
  overlay_filter: 0.5 # same as adding an opacity of 0.5 to a black background
  caption: "Photo credit: [**Unsplash**](https://unsplash.com)"
  # actions:
  #   - label: "More Info"
  #     url: "https://unsplash.com"
---

# 이탈 유저들에 대한 서비스 복귀 예측 모델링

## Concept Summary

![return_explaination](/assets/images/return_exp.jpg)

기존에 서비스 이탈자 전체에게 마케팅을 진행하는 것보다 더 효율적인 마케팅을 진행하기 위해 **전체 이탈자 중에서 마케팅 여부에 관계없이 복귀할 유저와 복귀를 하지 않을 유저를 선별하여 제외한다면 적은 비용으로 동일한 효과를 얻을 수 있지 않을까?** 라는 아이디어를 바탕으로 해당 프로젝트를 시작하게 되었습니다.

이를 위해서는 각 서비스 이탈자들의 복귀 확률을 계산해야 했으며, 복귀/미복귀를 label로 한 binary classification 문제로 접근하기로 결정하였습니다.

대상 서비스는 당시 마케팅 예정에 있던 RPG 서비스 중 하나를 선택하였으며 마케팅 시작일 기준 1년 이내 이탈자들의 복귀 확률을 산출하였습니다.

## Data Preparation

 데이터는 마케팅 시작일 기준 1년 동안의 데이터를 활용했으며 이용한 독립 변수 목록은 아래와 같습니다. 데이터는 zeppelin에서 pyspark문법과 SQL을 활용하여 불러왔습니다.

 * 과금액, 과금 횟수 등의 과금 관련 변수 7종
 * 접속 시간, 접속 횟수 등의 접속 관련 변수 11종
 * 캐릭터 개수, max 캐릭터 레벨 등 캐릭터 관련 변수 6종
 * 보스 몬스터 킬 수, 창고에 아이템 넣음 등의 인게임 변수 17종

 종속 변수인 복귀/미복귀는 특정 날짜 기준 이탈했던 유저들을 대상으로 현재 서비스를 이용하고 있는 유저는 복귀, 그렇지 않고 아직까지 이탈 중인 유저를 미복귀로 지정하였습니다. 

## Data Preprocessing

### Class Imbalancing

해당 산업에서 빈번하게 마주치는 문제 중 하나입니다. 보통 이탈 유저들의 복귀는 x% 수준으로 상당히 낮습니다. 서비스마다 다르지만 큰 차이는 보이지 않습니다. 이번 프로젝트에서 선정한 서비스는 다행히 상대적으로 높은 수준의 복귀율을 보이고 있지만 여전히 종속 변수에 대한 class 불균형 문제를 갖고 있었습니다. 

![class_imbalancing](/assets/images/imbalancing.jpg)

첫 번째로 접근한 방법은 random undersampling 이었습니다. 적은 label(복귀 유저 수)의 경우 데이터가 수만건이 되어 양은 충분하다고 생각했고 undersampling은 skewed dataset에서 더 효과적인 방법이라고 알려져 있기 때문에(A Dal Pozzolo, 2015) 첫 번째로 선택하였습니다. prototype으로 선택한 모델은 LGBM이었습니다. 

![after_rebalancing](/assets/images/balancing.jpg)


* After undersampling AUC : 0.512 -> 0.567

그 다음 적용한 rebalancing 방법은 SMOTE입니다. SMOTE는 현재는 모델링에서 가장 널리 알려져 있고 "잘 모르겠으면 Adam을 적용해라!" 하는 격언처럼 이용되고 있는 방법입니다. 

* After SMOTE AUC: 0.567 -> 0.688

이 외에도 class imbalancing에 대처하기 위한 여러가지 방법이 있지만 해당 결과를 바탕으로 다음 단계로 진행하였습니다.


### Correlation


모델을 크게 두 가지의 관점에서 만들었는데, 첫 번째는 모델에 대한 해석이 필요하지 않는 즉, **예측 확률값만이 필요**한 경우와 두 번째는 복귀에 유의미한 영향을 미치는 요인이 무엇인지 **해석이 필요**한 경우입니다. 
첫 번째 경우의 모델은 별다른 변수 선택을 거치지 않고 대부분의 독립 변수들을 이용하였습니다. 이는 추후에 MLops의 과정에서 전체 서비스와 상황별로 일반화하기 쉽다는 장점이 있습니다.

두 번째 경우는 상관 계수가 높은 변수들 중에서 서비스 차원에서 해석이 필요한 변수를 남기는 방식으로 진행하였습니다. 통계적 모델을 이용해서 검정 결과에 의존하는 방법도 있었지만, 해석이 필요한 경우는 보통 사업부와의 커뮤니케이션이 필요한 경우였기 때문에 p-value나 VIF, 신뢰구간에 의한 해석은 의사 소통을 더 어렵게 만든다고 생각하였습니다. 아래는 이번 프로젝트에서 진행한 독립 변수들 일부의 상관계수를 heatmap으로 표현한 것 입니다.

![corr_before](/assets/images/corr_before.jpg)

밝은색으로 표현된 부분은 변수간 상관계수가 높은 것을 의미합니다. 변수 제거의 조건을 상관 계수 0.5 ~ 0.7 다양한 기준으로 적용하여 확인하였으며 최종적으로는 0.7 이상인 변수들을 제거하기로 하였고, 서비스 차원에서 더 의미가 있는 변수를 선택하고 나머지를 제거하였습니다. 아래는 그 결과입니다.

![corr_after](/assets/images/corr_after.jpg)

일반적으로 ML 모델은 종속 변수와 독립 변수와의 선형성을 가정하지 않으며, 이론적으로 multicollinearity의 문제는 이러한 선형성의 가정이 필요한 모델에서 나오기 때문에 어느정도 자유롭다고 알려져 있습니다. 하지만 (L Toloşi, 2011) 등에 따르면 여전히 상관계수가 높은 독립 변수들은 bias의 측면에서 모델 적합에 어려움을 준다는 연구 결과들이 있습니다.
실제로도 이번 프로젝트의 데이터에서도 높은 상관계수를 갖는 변수들을 삭제한 후 약간의 validation 성능 향상이 있었습니다. 

* After Feature Selection AUC: 0.688 -> 0.693



## Modeling

모델링은 크게 **알고리즘의 선택**과 선택한 알고리즘에 대한 **hyper-parameter tuning**으로 나뉜다고 생각합니다. 제가 속한 조직은 정확도 0.1점을 올리기 위해 리소스를 투자하기 보다는 적당한 성능의 모델을 만들고 이를 통해 실제 마케팅을 진행하고 인사이트를 얻는데 초점이 맞춰진 조직입니다. 따라서, 모델링에 큰 시간을 투자하지 않았고 알고리즘의 선택은 동료 데이터 사이언티스트 분들과의 협의를 통해 LGBM으로 진행하였습니다. 사실 tuning에 대한 필요성도 많지 않았지만 LGBM이라는 모델이 hyper-parameter에 민감한 모델이기 때문에 이 부분은 간과할 수 없었습니다.


